# ðŸ”§ Troubleshooting - ProblÃ¨mes Courants

## âŒ ProblÃ¨me: Cellule 1 tourne dans le vide (pas d'output)

### SymptÃ´me
La cellule d'installation (`!pip install -q -U ...`) tourne indÃ©finiment sans aucun feedback :
- Pas d'erreur
- Pas de progression visible
- On dirait que Ã§a freeze

### Cause
Le flag `-q` (quiet mode) masque tout l'output de pip, donnant l'impression que rien ne se passe. L'installation prend rÃ©ellement **2-3 minutes** pour tÃ©lÃ©charger et installer les packages.

### âœ… Solution
**Le notebook a Ã©tÃ© corrigÃ©** : flag `-q` retirÃ© pour afficher la progression.

**Maintenant vous verrez :**
```
ðŸ“¦ Installation des packages (peut prendre 2-3 minutes)...

Collecting torch>=2.2.0
  Downloading torch-2.5.1-cp310-cp310-linux_x86_64.whl (1024 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1024/1024 MB 15.2 MB/s eta 0:00:00
Installing collected packages: torch
...
âœ… Installation terminÃ©e !
```

**Temps normal :**
- GPU T4/V100/A100 : 2-3 minutes
- PremiÃ¨re exÃ©cution : plus long (tÃ©lÃ©chargements)
- ExÃ©cutions suivantes : plus rapide (cache)

---

## âŒ Erreur: "No matching distribution found for torch==2.1.2"

### ProblÃ¨me
```
ERROR: Could not find a version that satisfies the requirement torch==2.1.2
ERROR: No matching distribution found for torch==2.1.2
```

### Cause
PyTorch 2.1.2 n'existe plus dans les dÃ©pÃ´ts pip (version obsolÃ¨te).

### âœ… Solution
**Le notebook a Ã©tÃ© corrigÃ©** avec des versions rÃ©centes :
- `torch>=2.2.0` (au lieu de `torch==2.1.2`)
- `transformers>=4.40.0`
- `peft>=0.10.0`
- `bitsandbytes>=0.43.0`

**Si vous utilisez une vieille version du notebook :**
1. Re-tÃ©lÃ©charger le notebook depuis ce repo
2. Ou modifier manuellement la cellule 2 :
   ```python
   !pip install -q -U torch>=2.2.0 transformers>=4.40.0 peft>=0.10.0 ...
   ```

---

## âŒ Erreur: "CUDA out of memory" sur Colab

### ProblÃ¨me
```
RuntimeError: CUDA out of memory. Tried to allocate X GB
```

### Solutions

#### Option 1 : RÃ©duire batch size
Dans la cellule aprÃ¨s vÃ©rification GPU, forcer un batch size plus petit :
```python
BATCH_SIZE = 2  # Au lieu de 4 ou 8
GRADIENT_ACCUM = 16  # Compenser (effective batch = 32)
```

#### Option 2 : RedÃ©marrer avec GPU plus puissant
1. Runtime > Disconnect and delete runtime
2. Runtime > Change runtime type > **A100 GPU** (ou V100)
3. Relancer "Run all"

#### Option 3 : RÃ©duire dataset
Utiliser seulement `schemes_levelA_base.jsonl` (300 exemples au lieu de 1200) :
```python
# Commenter la ligne d'augmentation
# dataset_augmented = load_dataset(...)
dataset_full = dataset_base  # Seulement 300 exemples
```

---

## âŒ Erreur: "SFTTrainer not found"

### ProblÃ¨me
```
ImportError: cannot import name 'SFTTrainer' from 'trl'
```

### Cause
Version de `trl` trop ancienne.

### Solution
```python
!pip install -U trl>=0.8.0
```

---

## âŒ Training trÃ¨s lent (>3h sur T4)

### Solutions

#### Option 1 : RÃ©duire epochs
```python
num_train_epochs=2  # Au lieu de 3
```

#### Option 2 : RÃ©duire dataset
Utiliser seulement 300 exemples base (au lieu de 1200).

#### Option 3 : Utiliser GPU plus rapide
Colab Pro permet d'accÃ©der Ã  A100 (10x plus rapide que T4).

---

## âŒ Eval loss > 1.0 (ne converge pas)

### ProblÃ¨me
AprÃ¨s training, la validation loss reste Ã©levÃ©e (>1.0).

### Causes possibles
1. **Learning rate trop Ã©levÃ©** â†’ RÃ©duire Ã  `1e-4` (au lieu de `2e-4`)
2. **Pas assez d'epochs** â†’ Augmenter Ã  4 ou 5
3. **Dataset corrompu** â†’ VÃ©rifier format JSONL

### Solution
Relancer training avec learning rate rÃ©duit :
```python
learning_rate=1e-4,  # Plus conservateur
num_train_epochs=4,  # Plus d'epochs
```

---

## âŒ LoRA ne charge pas correctement en local

### ProblÃ¨me
```python
PeftModel.from_pretrained(model, lora_path)
# Erreur ou pas d'amÃ©lioration vs base model
```

### Solutions

#### VÃ©rifier fichiers LoRA
```bash
ls -lh models/mistral-7b-philosophes-lora-final/
# Doit contenir:
# - adapter_config.json
# - adapter_model.safetensors
```

#### Forcer merge
```python
model = PeftModel.from_pretrained(model, lora_path)
model = model.merge_and_unload()  # Merge explicite
```

#### Tester avec infÃ©rence simple
```python
# Test rapide
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
result = pipe("SchÃ¨me : Modus Ponens\nContexte : Si P alors Q, or P\nApplique :")
print(result)
```

---

## âŒ Latence CPU > 30s par rÃ©ponse

### ProblÃ¨me
InfÃ©rence trop lente sur CPU (>30s par rÃ©ponse).

### Solutions

#### Option 1 : VÃ©rifier quantization 4-bit
```python
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,  # Doit Ãªtre True
    # ...
)
```

#### Option 2 : RÃ©duire max_new_tokens
```python
max_new_tokens=64,  # Au lieu de 128
```

#### Option 3 : Utiliser GPU
Si latence critique, dÃ©ployer sur Modal/HF GPU au lieu de CPU.

---

## âŒ Push vers HF Hub Ã©choue

### ProblÃ¨me
```
403 Forbidden: Token does not have write access
```

### Solution
1. Aller sur [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. CrÃ©er un **nouveau token** avec **write access** âœ…
3. Remplacer dans le notebook :
   ```python
   HF_TOKEN = "hf_NOUVEAU_TOKEN_AVEC_WRITE_ACCESS"
   ```

---

## âŒ ModÃ¨le gÃ©nÃ¨re seulement des zÃ©ros aprÃ¨s re-fine-tuning

### ProblÃ¨me
AprÃ¨s re-fine-tuning, le modÃ¨le gÃ©nÃ¨re des outputs corrompus (rÃ©pÃ©tition de zÃ©ros) :
```
ðŸ’¬ SPINOZA : [20000000000000000000000000000000000000000...
```

### Cause
**Catastrophic forgetting massif** causÃ© par :
- Re-fine-tuning sur dataset trop petit (ex: 23 exemples)
- Ratio dÃ©sÃ©quilibrÃ© : 1200 exemples initiaux â†’ 23 exemples correction
- Le modÃ¨le "oublie" tout ce qu'il a appris et surajuste sur les 23 exemples

### âœ… Solution
**TOUJOURS combiner datasets** lors du re-fine-tuning :

1. **Ratio 80/20 :**
   - 80% du dataset original (schÃ¨mes logiques)
   - 100% du dataset de correction (incarnation)
   - Exemple : 720 schÃ¨mes + 213 incarnation = 933 exemples

2. **Code correct :**
   ```python
   from datasets import concatenate_datasets

   # Prendre 80% du dataset original
   dataset_schemes_sample = dataset_schemes.shuffle(seed=42).select(range(int(len(dataset_schemes)*0.8)))

   # Combiner avec dataset correction
   dataset_combined = concatenate_datasets([dataset_schemes_sample, dataset_incarnation])
   ```

3. **ParamÃ¨tres adaptÃ©s :**
   - Learning rate normal : `2e-4` (pas rÃ©duit)
   - Epochs : 2-3 (pas 1 seul)
   - Monitoring : `eval_loss` tous les 20 steps

**Voir Section 8 du notebook** pour l'implÃ©mentation complÃ¨te.

---

## ðŸ“ž Aide SupplÃ©mentaire

Si aucune solution ne fonctionne :

1. **VÃ©rifier versions :**
   ```python
   import torch, transformers, peft
   print(f"torch: {torch.__version__}")
   print(f"transformers: {transformers.__version__}")
   print(f"peft: {peft.__version__}")
   ```

2. **Consulter documentation :**
   - [USAGE.md](USAGE.md) - Guide complet
   - [QUICKSTART.md](QUICKSTART.md) - Guide rapide
   - [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) - SynthÃ¨se projet

3. **Logs dÃ©taillÃ©s :**
   Dans le notebook, activer logging verbeux :
   ```python
   import logging
   logging.basicConfig(level=logging.INFO)
   ```

---

**DerniÃ¨re mise Ã  jour :** 20 novembre 2025
**Versions testÃ©es :** torch==2.8.0, transformers>=4.40.0, peft>=0.10.0, trl>=0.8.0
