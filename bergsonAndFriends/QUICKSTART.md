# âš¡ Quick Start - Fine-Tuning Mistral 7B

## ğŸ¯ Objectif
Fine-tuner Mistral 7B sur 1200 exemples de schÃ¨mes logiques philosophiques pour crÃ©er une version CPU-compatible (freemium tier) de Bergson and Friends.

---

## ğŸš€ 3 Ã‰tapes pour Lancer le Training

### 1ï¸âƒ£ PrÃ©parer Colab Pro (5 min)

1. Ouvrir [Google Colab](https://colab.research.google.com/)
2. **Upload :** `notebooks/train_mistral_7b_lora.ipynb`
3. **SÃ©lectionner GPU :** Runtime > Change runtime type > **A100 GPU** âš¡
4. **Upload datasets :**
   - Depuis Colab : Files (icÃ´ne gauche) > Upload
   - Uploader les 2 fichiers :
     - `data/FT/processed/schemes_levelA_base.jsonl` (545 KB)
     - `data/FT/processed/schemes_levelA_augmented.jsonl` (1.6 MB)

### 2ï¸âƒ£ Configurer le Notebook (2 min)

Dans la cellule **"2ï¸âƒ£ Configuration"**, remplacer :

```python
# Votre token Hugging Face (avec write access)
HF_TOKEN = "hf_xxxxxxxxxxxxxxxxxxxx"

# Votre username Hugging Face
HF_USERNAME = "FJDaz"  # Remplacer par votre username
```

**Obtenir un token HF :**
1. Aller sur [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. CrÃ©er un token avec **write access**
3. Copier le token dans le notebook

### 3ï¸âƒ£ Lancer le Training (30-45 min sur A100)

1. **Run All :** Runtime > Run all (ou Ctrl+F9)
2. â˜• **Pause cafÃ©** : 30-45 min sur A100 40GB
3. âœ… **RÃ©cupÃ©rer le modÃ¨le :**
   - **Option A :** Download `.zip` depuis Colab
   - **Option B :** Auto-push sur `huggingface.co/FJDaz/mistral-7b-philosophes-lora`

---

## ğŸ“Š RÃ©sultats Attendus

### MÃ©triques Training
- **Training loss (final) :** < 0.5
- **Eval loss (final) :** < 0.6
- **Temps A100 40GB :** 30-45 minutes âš¡
- **Taille LoRA :** ~250-350 MB

### MÃ©triques InfÃ©rence (aprÃ¨s tests)
- **Accuracy schÃ¨mes :** > 80%
- **Latence CPU 4-bit :** 5-15s par rÃ©ponse
- **RAM requise :** ~4 GB

---

## ğŸ§ª Test Rapide du ModÃ¨le (Local)

### Installer les dÃ©pendances
```bash
cd /Users/francois-jeandazin/NUX_FT/bergsonAndFriends
pip install -r requirements.txt
```

### DÃ©zipper et tester le LoRA
```bash
# DÃ©zipper le modÃ¨le tÃ©lÃ©chargÃ© depuis Colab
unzip mistral-7b-philosophes-lora-final.zip -d models/

# Lancer les benchmarks
python scripts/test_model.py --lora ./models/mistral-7b-philosophes-lora-final
```

**Output attendu :**
```
ğŸ¯ BENCHMARKS - Application SchÃ¨mes Logiques
===========================================================
ğŸ“š Test SPINOZA (3 questions)
[1/3]
Philosophe: SPINOZA
SchÃ¨me: Modus Ponens
RÃ©ponse: Donc l'Ã©lÃ¨ve est en servitude.
Latence: 8.2s
Correct: âœ…
...

ğŸ“Š STATISTIQUES GLOBALES
===========================================================
Total questions: 10
RÃ©ponses correctes: 8/10 (80.0%)
Latence moyenne: 7.5s
```

---

## ğŸ“ Philosophes Couverts

**Dataset :** 1200 exemples de schÃ¨mes logiques

| Philosophe | SchÃ¨mes Principaux | Exemples |
|------------|-------------------|----------|
| **Spinoza** | Modus Ponens, IdentitÃ© (Dieu=Nature), CausalitÃ© | 600 ex |
| **Bergson** | Opposition (durÃ©e/temps), Analogie (mÃ©lodie) | 300 ex |
| **Kant** | Distinction (phÃ©nomÃ¨ne/noumÃ¨ne), Condition | 300 ex |

---

## ğŸ“ˆ Comparaison Freemium Strategy

| Tier | ModÃ¨le | Infra | QualitÃ© | Latence | CoÃ»t |
|------|--------|-------|---------|---------|------|
| **Free** | Mistral 7B LoRA (CPU) | HF Space gratuit | ğŸŸ¡ Bonne (80%) | âš ï¸ 5-15s | âœ… Gratuit |
| **Premium** | Qwen 14B LoRA SNB (GPU) | Modal/HF GPU | âœ… Excellente (95%+) | âœ… 1-3s | ğŸ’° Pay-per-use |

**Objectif :** Valider que Mistral 7B LoRA (free tier) est **suffisamment bon** pour attirer des utilisateurs, tout en justifiant le premium (latence + qualitÃ©).

---

## ğŸ”— Ressources

- **Documentation complÃ¨te :** [USAGE.md](USAGE.md)
- **Architecture :** [README.md](README.md)
- **Config dÃ©taillÃ©e :** [configs/mistral_7b_lora.yaml](configs/mistral_7b_lora.yaml)
- **Notebook Colab :** [notebooks/train_mistral_7b_lora.ipynb](notebooks/train_mistral_7b_lora.ipynb)

---

## ğŸ’¡ Prochaines Ã‰tapes

1. âœ… **Training terminÃ©** â†’ Passer aux benchmarks complets
2. ğŸ“Š **Benchmarks OK** â†’ DÃ©ployer sur HF Space CPU gratuit
3. ğŸ¯ **Space deployed** â†’ Comparer avec Qwen 14B SNB (premium)
4. ğŸš€ **Comparaison faite** â†’ DÃ©cider stratÃ©gie freemium finale

---

**CrÃ©Ã© le :** 20 novembre 2025
**Config optimale :** Colab Pro A100 40GB, LoRA r=64, batch_size=8, epochs=3
**Temps total :** ~1h (setup 5min + training 45min + tests 10min)
